# 第3章 ニューラルネットワーク
このディレクトリにある `neuralnet_mnist.py` は、事前学習済みの重みを使って MNIST データセットのテストデータに対する分類精度を評価するためのシンプルなスクリプトです。

## 目的
- 事前学習済みパラメータ（`sample_weight.pkl`）を読み込み、MNIST のテストセットを用いて順伝播（推論）を行い、分類精度（Accuracy）を算出します。

## ファイル内の主要関数

- `get_data()`
	- MNIST データセットを読み込み、テスト用の入力 `x_test`（形状 (N, 784)）とラベル `t_test`（一次元配列）を返します。
	- 内部で `load_mnist(normalize=True, flatten=True, one_hot_label=False)` を呼び出します。

- `init_network()`
	- カレントワークディレクトリにある `sample_weight.pkl` を開いて、重みとバイアスを含む辞書 `network` を読み込みます。
	- `network` は `'W1','W2','W3','b1','b2','b3'` のようなキーを持つことを前提としています。

- `predict(network, x)`
	- 単一の入力ベクトル `x` に対して順伝播を実行します。
	- 中間層の活性化は `sigmoid`、出力層には `softmax` を使い、確率ベクトルを返します（例: 10 クラスの場合は長さ 10 のベクトル）。
	- 現状は単一入力向け（1D の `x`）の実装です。バッチ処理（複数入力）に対応させるには行列演算に合わせて修正してください。

## 実行前の準備
1. MNIST データが利用できること（`deep_learning/data` に適切なデータがあるか、`dataset/mnist.py` がダウンロード処理を持っているかを確認）。
2. 事前学習済みパラメータ `sample_weight.pkl` が `ch03` のカレントディレクトリまたはスクリプト実行時のカレントディレクトリに配置されていること。

## 実行方法（Docker コンテナ内）
リポジトリに同梱の `docker-compose` を使う場合の最短手順:

```powershell
# コンテナ内でスクリプトを実行
docker exec -it deep_learning_training /bin/bash -lc "python /app/workspace/ch03/neuralnet_mnist.py"
```

## 期待される出力
- スクリプトはネットワーク辞書を `print()` で表示した後、最終的に Accuracy を表示します。（※実際の値は `sample_weight.pkl` の品質とデータの前処理に依存します）

```
Accuracy:0.9352
```

## 前処理と正規化について

このスクリプトでは `load_mnist(normalize=True, flatten=True, one_hot_label=False)` を用いています。ここでの「正規化（normalize）」とその理由、一般的な前処理について説明します。

- 正規化 (Normalization)
	- `normalize=True` にすると、MNIST の画素値（元は 0〜255 の整数）は 0.0〜1.0 の実数にスケーリングされます。
	- 理由: ニューラルネットワークの学習や推論では、入力のスケールを揃えることで勾配計算の安定性が向上し、収束が速くなることが多いです。活性化関数（sigmoid や tanh など）は入力が大きいと飽和しやすく、正規化はこれを緩和します。

- 平滑化や中心化（オプション）
	- より進んだ前処理として平均値を引いてゼロ中心化（zero-centering）したり、標準偏差で割ってスケーリング（標準化）する方法があります。例えば画像全体の平均と標準偏差を使って (x - mean) / std を行う手法です。
	- これらはデータセットやモデルにより有効性が変わりますが、畳み込みニューラルネットワーク（CNN）やバッチ正規化を使う場合にも一般的に有効です。

- 画像の型と dtype
	- `normalize=True` を使うと float 系の配列になります。モデルの重みと計算の精度に応じて `float32` を明示するとメモリと計算速度のバランスが良くなります。

- 実践上の注意点
	- 学習時と推論時で同じ前処理を必ず行ってください（学習時に行った標準化のパラメータを保存しておき、推論時に同じ値で復元する）。
	- 外れ値や欠損がある場合は事前に処理してください（MNIST では通常不要）。
	- ラベルの表現（ワンホットか整数か）によって損失関数の選択が変わります（例: one-hot ラベルなら categorical_crossentropy、整数ラベルなら sparse_crossentropy に相当）。

このセクションを README に追加することで、`normalize=True` の意味と、入力データをモデルに渡す前の前処理の重要性が明確になります。